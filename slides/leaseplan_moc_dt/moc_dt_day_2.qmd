---
title: "MoC & Downturn LGD"
subtitle: "Day 2"
# author: "Pieter van den Berg"
date: last-modified
date-format: long
format: eduquant-slides-revealjs
---

## Day 2

::: columns
::: {.column width="40%"}
*13:00*

*13:30*

*14:15*

*15:00*

*15:15*

*16:00*

*16:45*
:::

::: {.column width="60%"}
Quiz & Recap

General Estimation Error

Deficiencies

*Break*

Appropriate Adjustments

Additional Uncertainties

Case Study Explanation
:::
:::

# Recap of day 1

## Risk Parameter Quantification

:::: columns

::: {.column width="50%" .r-fit-text}

Type of Exposures
: homogeneously managed, comparable risk characteristics

Reference dates
: Date to which realised values are aggregated

Calibration Target
: long-run average (LRA) default rate, (LRA/DT) LGD, CCF calculated based on RDS prior to adjustments

Appropriate Adjustment
: Modeled effect on CT of drivers of non-representativeness & other sources of bias

Appropriately Adjusted Calibration Target
: Calibration Target adjusted for biases

:::

::: {.column width="50%" .r-fit-text}
![](/media/risk_quantification.drawio.svg)
:::

::::

# MoC Quantification

## MoC Quantification {auto-animate=true}

:::: columns

::: {.column width="65%" .r-fit-text data-id="plo"}

*Initial* Calibration Target (CT)
: long-run average (LRA) default rate, (LRA/DT) LGD, CCF ~calculated~ estimated based on RDS prior to adjustments

MoC C
: Margin to account for statistical uncertainty of calibration target estimate in the absence of potential biases due to deficiencies

Deficiency
: Source of bias relative to initial calibration target

Appropriately adjusted calibration target
: Calibration target adjusted for biases due to deficiencies

MoC B
: Margin to account for additional uncertainty due to adjustment for non-representativeness

MoC A
: Margin to account for additional uncertainty due to other deficiencies
:::

::: {.column width="35%" .r-fit-text}
![](/media/risk_quantification_moc.drawio.svg)
:::

::::


## MoC Quantification {auto-animate=true}


:::: columns

::: {.column width="65%" .r-fit-text data-id="plo"}

MoC Categories (A, B, C)
:  allocation of uncertainties for MoC quantification


(Model) Risk Appetite
: Sets (additional) capital requirements in relation to credit risk due to model uncertainty

Level of conservatism
: how the MoC relates to the estimation uncertainty; e.g., a _confidence level_ 

MoC A, B, C
: required to be quantified, applied, reported, monitored separately

:::

::: {.column width="35%" .r-fit-text data-id="plo"}
![](/media/moc_unc_cons.drawio.svg)
:::

::::



# General Estimation Error

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: {data-id="sdf" }
The statistical estimator
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

:::

::: {.column width="50%" .r-fit-text}
::: {.callout-note}
## EBA/GL/2017/16 $\S$ 42
_The final MoC on a risk parameter estimate should reflect the uncertainty of the estimation in all of the following categories: $\small{[\cdots]}$ Category C: the **general estimation error**._
:::
::: {data-id="ert" .callout-note}
## EBA/GL/2017/16 $\S$ 43. 
_In order to quantify MoC institutions should $\small{[\cdots]}$ quantify the general estimation error of category C referred to in paragraph 42 associated with the underlying estimation method at least for every calibration segment; the MoC for the general estimation error should reflect the dispersion of the distribution of the **statistical estimator**._
:::
:::
::::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text}

::: {data-id="sdf" }
The statistical estimator
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

:::


::: {.column width="50%" .r-fit-text}

```{r adj-dist}
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 5

library(ggplot2) 
library(ggdist)
library(distributional)
#bg <- rgb(255,255,230, maxColorValue = 255)
bg <- 'transparent'
df <- data.frame(
  group = c("initial", "adjusted", "adjusted"), mu = c(0,0.5,0.5), sd = c(0.1,0.1,0.2), alpha=c(1, 0,1))

ggplot(df, aes(y = group, xdist = dist_normal(mu, sd))) +
  stat_halfeye(aes(fill = stat(level), alpha=alpha)) +
  geom_segment(data=df[2,],
    aes(x = 0, xend = mu, yend = group), 
    color = "rosybrown", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed"), position=position_nudge(y=-0.05)) +
  geom_segment(data=df[3,],
    aes(x = mu-0.5*sd, xend = mu+0.5*sd, yend = group), 
    color = "skyblue", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed", ends="both" ), position=position_nudge(y=-0.1)) +
  geom_vline(xintercept = df[1,]$mu, color = "gray", linetype="dashed" )+
  geom_vline(xintercept = df[2,]$mu, color = "rosybrown", linetype="dashed" )+
  scale_fill_manual(values = c("gray85", "skyblue"), na.value = "gray85", guide = "none") +
  scale_y_discrete() +
  scale_alpha(guide="none", range = c(0.33,0.75)) +
  scale_x_continuous(guide = "none") +
  labs(x = "", y = "") + 
  theme(
    panel.background = element_rect(fill=bg), 
    plot.background = element_rect(fill=bg, color=NA), 
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    legend.background = element_rect(fill=bg), 
    legend.box.background = element_rect(fill=bg) )
```

:::
::::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: {data-id="sdf" }
The statistical estimator
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

 * MoC C "reflects" general estimation error
 * EBA explicitly allows for flexibility
 * ECB more explicit

:::


::: {.column width="50%" .r-fit-text}

::: {data-id="ert" .callout-note}
## EBA/GL/2017/16 $\S$ 43. 
_In order to quantify MoC institutions should $\small{[\cdots]}$ quantify the general estimation error of category C referred to in paragraph 42 associated with the underlying estimation method at least for every calibration segment; the MoC for the general estimation error should reflect the dispersion of the distribution of the **statistical estimator**._
:::
::: {data-id="ert2" .callout-note}
## ECB Guide to Internal Models (CR) $\S$ 140 
*(a) This MoC should be based on the distribution of the estimator, which is the average of one-year default rates of the grade/pool across time (i.e. the distribution of $(\Sigma\text{DR}_t)/T$, considering that the uncertainty is primarily driven by the statistical uncertainty of each one-year default rate and the length of the time series. As a result, it is expected that **the lower the number of observations per grade and the shorter the time series are, the higher the MoC** of the grade should be.*

_(b) Similarly, for LGD and CCF, $\small{[\cdots]}$  uncertainty is primarily driven by the statistical uncertainty of the observations used to compute the long-run and downturn estimates and the length of the time series_
:::

:::
::::


## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text}
::: {data-id="sdf" }
[The statistical estimator]{style="color: teal;"}
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

:::{data-id="ert32"}
$$\text{DR}_{\text{LRA}} = \frac{1}{R}\sum_{r=1\dots R}\frac{1}{N_\mathbf{L}(t_r)}\sum_{i\in\mathbf{L}} \text{D}_i(t_r)$$

$$\text{LGD}_{\text{LRA}} = \frac{1}{N_\mathbf{L}}\sum_{i\in\mathbf{L}} \text{RLGD}_i$$

$$\text{CCF}_{\text{LRA}} = \frac{1}{R}\sum_{r=1\dots R}\frac{1}{N_\mathbf{L}(t_r)}\sum_{i\in\mathbf{L}} \text{CCF}_i(t_r)$$
:::
:::


::: {.column width="50%" .r-fit-text}

![](`r knitr::fig_chunk('adj-dist', 'png')`)


:::
::::



## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\text{var}(\frac{1}{N_L(t_r)}\sum_{i\in\mathbf{L}} \text{D}_i(t_r))$$

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}}\text{var}(\sum_{i\in\mathbf{L}} \text{RLGD}_i)$$

$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\text{var}(\frac{1}{N_L(t_r)}\sum_{i\in\mathbf{L}} \text{CCF}_i(t_r))$$
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('adj-dist', 'png')`)

:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 
:::


## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
[$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N^2_r}\text{var}(\sum_{i\in\mathbf{L}}\text{D}_{ir}))$$]{style="color: steelblue"}

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N^2_\mathbf{L}}\text{var}(\sum_{i\in\mathbf{L}} \text{RLGD}_i)$$

[$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\text{var}(\sum_{i\in\mathbf{L}}\text{CCF}_{ir}))$$]{style="color: steelblue"}
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('adj-dist', 'png')`)


:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_{ir}$, $\text{RLGD}_i$, $\text{CCF}_{ir}$ 

[Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)]{style="color: steelblue"}
:::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
[$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\pi_{r}(1-\pi_{r})$$]{style="color: steelblue"}

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}}\sigma^2(\text{RLGD})$$

$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\sigma_r^2(CCF))$$
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('adj-dist', 'png')`)

:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_{ir}$, $\text{RLGD}_{ir}$, $\text{CCF}_{ir}$ 

Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)

[Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$]{style="color: steelblue"}

:::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
[$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\pi_{r}(1-\pi_{r})$$]{style="color: steelblue"}

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}}\sigma^2(\text{RLGD})$$

[$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\sigma_r^2(CCF))$$]{style="color: steelblue"}
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('adj-dist', 'png')`)

:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_{ir}$, $\text{RLGD}_{ir}$, $\text{CCF}_{ir}$ 

Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

[Assuming known $N_r$, $R$]{style="color: steelblue"}
:::


## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
$$\hat{\sigma}^2(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}\text{DR}_{r}(1-\text{DR}_{r})$$

$$\hat{\sigma}^2(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}-1}s^2(\text{RLGD})$$

$$\hat{\sigma}^2(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}s_r^2(CCF_r))$$
:::
:::

::: {.column width="30%" .r-fit-text}
![](`r knitr::fig_chunk('adj-dist', 'png')`)
:::
::::


::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Assuming known $N_r$, $R$

[Unbiased estimators of the variance of the mean (Bessel's)]{style="color: steelblue"}

:::



## General Estimation Error {auto-animate=true}

:::{data-id="ert32"}
$\hat{\sigma}^2(\text{DR}_{\text{LRA}})$, $\hat{\sigma}^2(\text{LGD}_{\text{LRA}})$, $\hat{\sigma}^2(\text{CCF}_{\text{LRA}})$
:::

::: {.callout-warning .r-fit-text data-id="cvb"}
**Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ **

 * [Cond. independence of $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ assumed by required statistical estimator]{style="color: darkolivegreen"}
 * [Connected clients]{style="color: indianred"}

Assuming $R$ independent draws

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Unbiased estimators of the variance of the mean

:::

## General Estimation Error {auto-animate=true}

::: {.callout-warning .r-fit-text data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

**Assuming $R$ independent draws**

 * [Overlapping observation windows $\rightarrow$ auto-correlation]{style="color: indianred"}

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Unbiased estimators of the variance of the mean

:::

::: {data-id="ert" .callout-note}
## ECB Guide to Internal Models (CR) $\S$ 140 
_(a) $\small{[\cdots]}$ Institutions need to be aware of and deal adequately with the dependency between default rates over time on the quantification of the MoC, e.g. when using overlapping windows for the calculation of default rates._
:::


## General Estimation Error {auto-animate=true}

![](/media/rds_aggr_pd_overlap.drawio.svg)

::: {.callout-warning .r-fit-text data-id="cvb"}

**Assuming $R$ independent draws**

 * [Overlapping observation windows $\rightarrow$ auto-correlation]{style="color: indianred"}

:::


:::: columns
::: {.column width="50%" .r-fit-text }
#### Strategies 
 * Non-overlapping sample 
 * Non-overlapping resampling scheme
 * Explicitly model / correct for auto-correlation bias
:::
:::{.column width="5%" }
:::
:::{.column width="22.5%" .r-fit-text }
#### [pros]{style="color: darkolivegreen"}
 * simple
 * non-parametric
 * explicit
:::

:::{.column width="22.5%" .r-fit-text }

#### [cons]{style="color: indianred"}
 * biased
 * complex
 * possibly not identifiable
:::
::::


## General Estimation Error {auto-animate=true}

::: {.callout-warning .r-fit-text data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

Assuming $R$ independent draws

**Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$**

 * Sampling without replacement $\text{D}_r \sim \text{Hypergeometric}(N_r,\pi^{\prime}_r)$

Unbiased estimators of the variance of the mean

:::

::: {.callout-note .r-fit-text}
Due to fast convergence $\text{Hypergeometric}\rightarrow\text{Binomial}$, relevant for small $N_r$, large $\pi_r$ only.
:::

## General Estimation Error {auto-animate=true}

:::{data-id="ert32"}
$\hat{\sigma}^2(\text{DR}_{\text{LRA}})$, $\hat{\sigma}^2(\text{LGD}_{\text{LRA}})$, $\hat{\sigma}^2(\text{CCF}_{\text{LRA}})$
:::

::: {.callout-warning .r-fit-text data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

Assuming $R$ independent draws

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Assuming known $N_r$, $R$

**Biased estimators of the std err of the mean**

:::


## General Estimation Error {auto-animate=true}

:::: columns
:::{ .column width="60%" data-id="ert32" .r-fit-text}
$$\hat{\sigma}^2(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}\text{DR}_{r}(1-\text{DR}_{r})$$

$$\hat{\sigma}^2(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}-1}s^2(\text{RLGD})$$

$$\hat{\sigma}^2(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}s_r^2(CCF_r))$$
:::

:::{ .column width="40%" }
::: {.callout-warning .r-fit-text data-id="cvb"}
Biased estimators of the std err of the mean

 * E.g. if $s^2=0$ or $\text{DR}_r=0$
 * *Asympotically* unbiased estimators $\nsim$ uncertainty of specific estimate

:::
:::
::::



## General Estimation Error {auto-animate=true}

:::: columns
:::{ .column width="50%" data-id="ert32" .r-fit-text}
$$\frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}\text{DR}_{r}(1-\text{DR}_{r})$$
:::

:::{ .column width="50%" }
::: {.callout-warning .r-fit-text data-id="cvb"}
Biased estimators of the std err of the mean
:::
:::
::::
:::: columns
:::{ .column width="50%" data-id="ert32" .r-fit-text #vcenter}

$$\int^\alpha \text{Beta}(D_r + \frac{1}{2}, N_r – D_r + \frac{1}{2})$$


:::

::: {.column width="50%" #vcenter}
::: {.callout-note .r-fit-text data-id="cvb2"}
Posterior interval based on non-informative ([conservative]{style="color:indianred"}) Jeffrey's prior for binomial parameter
::: 
:::
::::

# Deficiencies

## Deficiencies {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: {data-id="qwe" }
Deficiency
: any driver of (potential) bias of the statistical estimator relative to the estimated risk parameter

:::

:::

::: {.column width="50%" .r-fit-text}
::: {.callout-note data-id="tre"}
## EBA/GL/2017/16 $\S$ 36. 
_Institutions should identify all deficiencies related to the estimation of risk parameters that lead to a bias in the quantification of those parameters or to an increased uncertainty that is not fully captured by the general estimation error_
:::
:::
::::


## Generic process


:::: columns

::: {.column width="50%" .r-fit-text }

::: {data-id="qwe" }
Deficiency
: any driver of (potential) bias of the statistical estimator relative to the estimated risk parameter

Remediation
: the deficiency is removed

Mitigation
: appropriate adjustment + MoC; the deficiency is not removed
:::

:::

::: {.column width="50%" .r-fit-text}
![](/media/moc_aa_generic.drawio.drawio.svg)
:::
::::


## Identification

## Remediation

## Mitigation

# Appropriate Adjustments

# Additional Uncertainties

# MoC Quantification

# Case Study Explanation