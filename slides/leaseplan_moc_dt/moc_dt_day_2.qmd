---
title: "MoC & Downturn LGD"
subtitle: "Day 2"
# author: "Pieter van den Berg"
date: last-modified
date-format: long
format: eduquant-slides-revealjs
---

## Day 2

::: columns
::: {.column width="40%"}
*13:00*

*13:30*

*14:00*

*15:00*

*15:15*

*16:00*

*16:45*
:::

::: {.column width="60%"}
Recap

MoC Quantification

General Estimation Error

*Break*

Treatment of deficiencies

Data quality & completeness

Representativeness + Case Study
:::
:::

# Recap of day 1

## Risk Parameter Quantification

:::: columns

::: {.column width="50%" .r-fit-text}

Type of Exposures
: homogeneously managed, comparable risk characteristics

Reference dates
: Date to which realised values are aggregated

Calibration Target
: long-run average (LRA) default rate, (LRA/DT) LGD, CCF calculated based on RDS prior to adjustments

Appropriate Adjustment
: Modeled effect on CT of drivers of non-representativeness & other sources of bias

Appropriately Adjusted Calibration Target
: Calibration Target adjusted for biases

:::

::: {.column width="50%" .r-fit-text}
![](/media/risk_quantification.drawio.svg)
:::

::::

# MoC Quantification

## MoC Quantification {auto-animate=true}

:::: columns

::: {.column width="65%" .r-fit-text data-id="plo"}

*Initial* Calibration Target (CT)
: long-run average (LRA) default rate, (LRA/DT) LGD, CCF ~calculated~ estimated based on RDS prior to adjustments

MoC C
: Margin to account for statistical uncertainty of calibration target estimate in the absence of potential biases due to deficiencies

Deficiency
: Source of bias relative to initial calibration target

Appropriately adjusted calibration target
: Calibration target adjusted for biases due to deficiencies

MoC B
: Margin to account for additional uncertainty due to adjustment for non-representativeness

MoC A
: Margin to account for additional uncertainty due to other deficiencies
:::

::: {.column width="35%" .r-fit-text}
![](/media/risk_quantification_moc.drawio.svg)
:::

::::


## MoC Quantification {auto-animate=true}


:::: columns

::: {.column width="65%" .r-fit-text data-id="plo"}

MoC Categories (A, B, C)
:  allocation of uncertainties for MoC quantification


(Model) Risk Appetite
: Sets (additional) capital requirements in relation to credit risk due to model uncertainty

Level of conservatism
: how the MoC relates to the estimation uncertainty; e.g., a _confidence level_ 

MoC A, B, C
: required to be quantified, applied, reported, monitored separately

:::

::: {.column width="35%" .r-fit-text data-id="plo"}
![](/media/moc_unc_cons.drawio.svg)
:::

::::

## MoC Quantification {auto-animate=true}


:::: columns

::: {.column width="65%" .r-fit-text data-id="plo"}

::: {.callout-note}
## EBA/GL/2017/16 $\S$ 42
_The final MoC on a risk parameter estimate should reflect the uncertainty of the estimation in all of the following categories: $\small{[\cdots]}$_
:::
::: {.callout-note}
## EBA/GL/2017/16 $\S$ 43
_(ii) the MoC at category level related to the appropriate adjustments is proportionate to the uncertainty around these adjustments;_
::: 
::: {.callout-note}
## EBA/GL/2017/16 $\S$ 43
_(ii) the MoC at category level related to the appropriate adjustments is proportionate to the uncertainty around these adjustments;_
::: 

:::

::: {.column width="35%" .r-fit-text data-id="plo"}
![](/media/moc_unc_cons.drawio.svg)
:::

::::

::: {.callout-warning}
 * MoC should reflect uncertainty attributed to all deficiencies in category
 * **not**: Each deficiency should have separate MoC/adjustment
::: 


# General Estimation Error

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: {data-id="sdf" }
The statistical estimator
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

:::

::: {.column width="50%" .r-fit-text}
::: {.callout-note}
## EBA/GL/2017/16 $\S$ 42
_The final MoC on a risk parameter estimate should reflect the uncertainty of the estimation in all of the following categories: $\small{[\cdots]}$ Category C: the **general estimation error**._
::: 

::: {.callout-note}
## EBA/GL/2017/16 $\S$ (p18)
_The reference to statistical variance has been avoided in order to not impose a fixed methodology, which might for example lead to disproportionate MoC for low default portfolios._
:::
:::
::::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text}

::: {data-id="sdf" }
The statistical estimator
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

::: {.callout-warning }
The MoC C should reflect the general estimation error *after adjustments*.
:::
:::


::: {.column width="50%" .r-fit-text}

```{r unadj-dist}
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 5

library(ggplot2) 
library(ggdist)
library(distributional)
#bg <- rgb(255,255,230, maxColorValue = 255)
bg <- 'transparent'
df <- data.frame(
  group = c("initial", "adjusted"), mu = c(0,0.5), sd = c(0.1,0.1))

ggplot(df, aes(y = group, xdist = dist_normal(mu, sd))) +
  stat_halfeye(aes(fill = stat(level))) +
  geom_segment(data=df[2,],
    aes(x = 0, xend = mu, yend = group), 
    color = "rosybrown", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed"), position=position_nudge(y=-0.05)) +
  geom_vline(xintercept = df[1,]$mu, color = "gray", linetype="dashed" )+
  geom_vline(xintercept = df[2,]$mu, color = "rosybrown", linetype="dashed" )+
  scale_fill_manual(values = c("gray85", "skyblue"), na.value = "gray85", guide = "none") +
  scale_y_discrete() +
  scale_x_continuous(guide = "none",  limits = c(-0.5,1.25)) +
  labs(x = "", y = "") + 
  theme(
    panel.background = element_rect(fill=bg), 
    plot.background = element_rect(fill=bg, color=NA), 
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    legend.background = element_rect(fill=bg), 
    legend.box.background = element_rect(fill=bg) )
```

:::
::::



## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: {data-id="sdf" }
The statistical estimator
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::
::: {.callout-warning }
MoC C *reflects* general estimation error

EBA GL explicitly allows for flexibility

EGIM adds proportionality requirement
:::
:::


::: {.column width="50%" .r-fit-text}

::: {.callout-note}
## EBA/GL/2017/16 $\S$ 42
_The final MoC on a risk parameter estimate should reflect the uncertainty of the estimation in all of the following categories: $\small{[\cdots]}$ Category C: the **general estimation error**._
::: 

::: {data-id="ert2" .callout-note}
## ECB Guide to Internal Models (CR) $\S$ 140 
*(a) This MoC should be based on the distribution of the estimator $\small{[\cdots]}$  considering that the uncertainty is primarily driven by the statistical uncertainty of each one-year default rate and the length of the time series. As a result, it is expected that **the lower the number of observations per grade and the shorter the time series are, the higher the MoC** of the grade should be.*

_(b) Similarly, for LGD and CCF, $\small{[\cdots]}$  uncertainty is primarily driven by the statistical uncertainty of the observations used to compute the long-run and downturn estimates and the length of the time series_
:::

:::
::::


## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text}
::: {data-id="sdf" }
[The statistical estimator]{style="color: teal;"}
: Calibration Target; (weighted) average default/loss/conversion rate

General estimation error
: Uncertainty not due to deficiencies; standard error of statistical estimator
:::

:::{data-id="ert32"}
$$\text{DR}_{\text{LRA}} = \frac{1}{R}\sum_{r=1\dots R}\frac{1}{N_\mathbf{L}(t_r)}\sum_{i\in\mathbf{L}} \text{D}_i(t_r)$$

$$\text{LGD}_{\text{LRA}} = \frac{1}{N_\mathbf{L}}\sum_{i\in\mathbf{L}} \text{RLGD}_i$$

$$\text{CCF}_{\text{LRA}} = \frac{1}{R}\sum_{r=1\dots R}\frac{1}{N_\mathbf{L}(t_r)}\sum_{i\in\mathbf{L}} \text{CCF}_i(t_r)$$
:::
:::


::: {.column width="50%" .r-fit-text}

![](`r knitr::fig_chunk('unadj-dist', 'png')`)


:::
::::



## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\text{var}(\frac{1}{N_L(t_r)}\sum_{i\in\mathbf{L}} \text{D}_i(t_r))$$

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}}\text{var}(\sum_{i\in\mathbf{L}} \text{RLGD}_i)$$

$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\text{var}(\frac{1}{N_L(t_r)}\sum_{i\in\mathbf{L}} \text{CCF}_i(t_r))$$
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('unadj-dist', 'png')`)

:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 
:::


## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
[$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N^2_r}\text{var}(\sum_{i\in\mathbf{L}}\text{D}_{ir}))$$]{style="color: steelblue"}

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N^2_\mathbf{L}}\text{var}(\sum_{i\in\mathbf{L}} \text{RLGD}_i)$$

[$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\text{var}(\sum_{i\in\mathbf{L}}\text{CCF}_{ir}))$$]{style="color: steelblue"}
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('unadj-dist', 'png')`)


:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_{ir}$, $\text{RLGD}_i$, $\text{CCF}_{ir}$ 

[Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)]{style="color: steelblue"}
:::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
[$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\pi_{r}(1-\pi_{r})$$]{style="color: steelblue"}

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}}\sigma^2(\text{RLGD})$$

$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\sigma_r^2(CCF))$$
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('unadj-dist', 'png')`)

:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_{ir}$, $\text{RLGD}_{ir}$, $\text{CCF}_{ir}$ 

Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)

[Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$]{style="color: steelblue"}

:::

## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
[$$\text{var}(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\pi_{r}(1-\pi_{r})$$]{style="color: steelblue"}

$$\text{var}(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}}\sigma^2(\text{RLGD})$$

[$$\text{var}(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r}\sigma_r^2(CCF))$$]{style="color: steelblue"}
:::
:::

::: {.column width="30%" .r-fit-text}

![](`r knitr::fig_chunk('unadj-dist', 'png')`)

:::
::::

::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_{ir}$, $\text{RLGD}_{ir}$, $\text{CCF}_{ir}$ 

Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

[Assuming known $N_r$, $R$]{style="color: steelblue"}
:::


## General Estimation Error {auto-animate=true}

:::: columns

::: {.column width="70%" .r-fit-text}

:::{data-id="ert32"}
$$\hat{\sigma}^2(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}\text{DR}_{r}(1-\text{DR}_{r})$$

$$\hat{\sigma}^2(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}-1}s^2(\text{RLGD})$$

$$\hat{\sigma}^2(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}s_r^2(CCF_r))$$
:::
:::

::: {.column width="30%" .r-fit-text}
![](`r knitr::fig_chunk('unadj-dist', 'png')`)
:::
::::


::: {.callout-note data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

Assuming $R$ independent draws ($\text{cov}(\text{X}_r,\text{X}_s)_{r\neq s}\rightarrow 0$)

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Assuming known $N_r$, $R$

[Unbiased estimators of the variance of the mean (Bessel's)]{style="color: steelblue"}

:::



## General Estimation Error {auto-animate=true}

:::{data-id="ert32"}
$\hat{\sigma}^2(\text{DR}_{\text{LRA}})$, $\hat{\sigma}^2(\text{LGD}_{\text{LRA}})$, $\hat{\sigma}^2(\text{CCF}_{\text{LRA}})$
:::

::: {.callout-warning .r-fit-text data-id="cvb"}
**Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ **

 * [Cond. independence of $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ assumed by required statistical estimator]{style="color: darkolivegreen"}
 * [Connected clients]{style="color: indianred"}

Assuming $R$ independent draws

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Unbiased estimators of the variance of the mean

:::

## General Estimation Error {auto-animate=true}

::: {.callout-warning .r-fit-text data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

**Assuming $R$ independent draws**

 * [Overlapping observation windows $\rightarrow$ auto-correlation]{style="color: indianred"}

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Unbiased estimators of the variance of the mean

:::

::: {data-id="ert" .callout-note}
## ECB Guide to Internal Models (CR) $\S$ 140 
_(a) $\small{[\cdots]}$ Institutions need to be aware of and deal adequately with the dependency between default rates over time on the quantification of the MoC, e.g. when using overlapping windows for the calculation of default rates._
:::


## General Estimation Error {auto-animate=true}

![](/media/rds_aggr_pd_overlap.drawio.svg)

::: {.callout-warning .r-fit-text data-id="cvb"}

**Assuming $R$ independent draws**

 * [Overlapping observation windows $\rightarrow$ auto-correlation]{style="color: indianred"}

:::


:::: columns
::: {.column width="50%" .r-fit-text }
#### Strategies 
 * Non-overlapping sample 
 * Non-overlapping resampling scheme
 * Explicitly model / correct for auto-correlation bias
:::
:::{.column width="5%" }
:::
:::{.column width="22.5%" .r-fit-text }
#### [pros]{style="color: darkolivegreen"}
 * simple
 * non-parametric
 * explicit
:::

:::{.column width="22.5%" .r-fit-text }

#### [cons]{style="color: indianred"}
 * biased
 * complex
 * possibly not identifiable
:::
::::

::: {.callout-warning appearance="default"}
## Deficiency
Method of selecting reference dates leads to a bias $\rightarrow$ methodological deficiency (MoC A)
:::

## General Estimation Error {auto-animate=true}

::: {.callout-warning .r-fit-text data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

Assuming $R$ independent draws

**Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$**

 * Sampling without replacement $\text{D}_r \sim \text{Hypergeometric}(N_r,\pi^{\prime}_r)$

Unbiased estimators of the variance of the mean

:::

::: {.callout-note .r-fit-text}
Due to fast convergence $\text{Hypergeometric}\rightarrow\text{Binomial}$, relevant for small $N_r$, large $\pi_r$ only.
:::

## General Estimation Error {auto-animate=true}

:::{data-id="ert32"}
$\hat{\sigma}^2(\text{DR}_{\text{LRA}})$, $\hat{\sigma}^2(\text{LGD}_{\text{LRA}})$, $\hat{\sigma}^2(\text{CCF}_{\text{LRA}})$
:::

::: {.callout-warning .r-fit-text data-id="cvb"}
Assuming i.i.d. $\text{D}_i$, $\text{RLGD}_i$, $\text{CCF}_i$ 

Assuming $R$ independent draws

Assuming $\text{D}_{ir} \sim \text{Binomial}(1,\pi_r)$

Assuming known $N_r$, $R$

**Biased estimators of the std err of the mean**

:::


## General Estimation Error {auto-animate=true}

:::: columns
:::{ .column width="60%" data-id="ert32" .r-fit-text}
$$\hat{\sigma}^2(\text{DR}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}\text{DR}_{r}(1-\text{DR}_{r})$$

$$\hat{\sigma}^2(\text{LGD}_{\text{LRA}}) = \frac{1}{N_\mathbf{L}-1}s^2(\text{RLGD})$$

$$\hat{\sigma}^2(\text{CCF}_{\text{LRA}}) = \frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}s_r^2(CCF_r))$$
:::

:::{ .column width="40%" }
::: {.callout-warning .r-fit-text data-id="cvb"}
Biased estimators of the std err of the mean

 * E.g. if $s^2=0$ or $\text{DR}_r=0$
 * *Asympotically* unbiased estimators $\nsim$ uncertainty of specific estimate

:::
:::
::::



## General Estimation Error {auto-animate=true}

:::: columns
:::{ .column width="50%" data-id="ert32" .r-fit-text}
$$\frac{1}{R^2}\sum_{r=1\dots R}\frac{1}{N_r-1}\text{DR}_{r}(1-\text{DR}_{r})$$
:::

:::{ .column width="50%" }
::: {.callout-warning .r-fit-text data-id="cvb"}
Biased estimators of the std err of the mean
:::
:::
::::
:::: columns
:::{ .column width="50%" data-id="ert32" .r-fit-text #vcenter}

$$\int^\alpha \text{Beta}(D_r + \frac{1}{2}, N_r – D_r + \frac{1}{2})$$


:::

::: {.column width="50%" #vcenter}
::: {.callout-note .r-fit-text data-id="cvb2"}
Posterior interval based on non-informative ([conservative]{style="color:indianred"}) Jeffrey's prior for binomial parameter
::: 
:::
::::


## General Estimation Error {auto-animate=true}

#### Level of quantification

 *  calibration level $\rightarrow$ level of MoC quantification
 * support assumption of constant estimation error
    + in particular for continuous estimates

::: {.callout-note}
## ECB Guide to Internal Models (CR) $\S$ 140 
_(a) $\small{[\cdots]}$ When calibration is performed at calibration segment level, the general estimation error may be computed at that level when the statistical uncertainty/sampling error is not significantly different across grades or PD sub-ranges._
:::

## General Estimation Error {auto-animate=true}

::: fragment
::: {.callout-important icon=true appearance="default" .r-fit-text}
## Common pitfalls
 * Calculating general estimation error before appropriate adjustments
 * Overrides / waivers on general estimation errors for low-default portfolios
 * MoC C of zero in zero-default grades
 * MoC C proportional to risk parameter values without proper substantiation
 * Constant MoC C without proper substantiation
:::
:::

# Treatment of deficiencies

## Treatment of deficiencies {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: data-id="qwe" 
Deficiency
: any driver of potential bias and increased uncertainty

Bias in the quantification
: Effect of the deficiency on the statistical estimator relative to the estimated risk parameter (may be $\approx 0$)
:::

:::

::: {.column width="50%" .r-fit-text}
::: {.callout-note data-id="tre"}

### EBA/GL/2017/16 $\S$ 36. 
_Institutions should identify all deficiencies related to the estimation of risk parameters that lead to a bias in the quantification of those parameters or to an increased uncertainty that is not fully captured by the general estimation error_
:::

::: fragment
![](`r knitr::fig_chunk('unadj-dist', 'png')`)
:::

:::
::::

## Treatment of deficiencies {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: data-id="qwe" 
Deficiency
: any driver of potential bias and increased uncertainty

Bias in the quantification
: Effect of the deficiency on the statistical estimator relative to the estimated risk parameter (may be $\approx 0$)
:::

::: data-id="qwe2" 
Additional uncertainty
: uncertainty attributed to uncertainty in the estimated effect size

Not captured by the general estimation error
: non-zero for $N_r, R \rightarrow \infty$
:::
:::

::: {.column width="50%" .r-fit-text}
::: {.callout-note data-id="tre"}
### EBA/GL/2017/16 $\S$ 36. 
_Institutions should identify all deficiencies related to the estimation of risk parameters that lead to a bias in the quantification of those parameters or to an increased uncertainty that is not fully captured by the general estimation error_
:::


```{r adj-dist}
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 5

library(ggplot2) 
library(ggdist)
library(distributional)
#bg <- rgb(255,255,230, maxColorValue = 255)
bg <- 'transparent'
df <- data.frame(
  group = c("initial", "adjusted", "adjusted"), mu = c(0,0.5,0.5), sd = c(0.1,0.1,0.2), alpha=c(1, 0,1))

ggplot(df, aes(y = group, xdist = dist_normal(mu, sd))) +
  stat_halfeye(aes(fill = stat(level), alpha=alpha)) +
  geom_segment(data=df[2,],
    aes(x = 0, xend = mu, yend = group), 
    color = "rosybrown", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed"), position=position_nudge(y=-0.05)) +
  geom_segment(data=df[3,],
    aes(x = mu-0.5*sd, xend = mu+0.5*sd, yend = group), 
    color = "skyblue", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed", ends="both" ), position=position_nudge(y=-0.1)) +
  geom_vline(xintercept = df[1,]$mu, color = "gray", linetype="dashed" )+
  geom_vline(xintercept = df[2,]$mu, color = "rosybrown", linetype="dashed" )+
  scale_fill_manual(values = c("gray85", "skyblue"), na.value = "gray85", guide = "none") +
  scale_y_discrete() +
  scale_alpha(guide="none", range = c(0.33,0.75)) +
  scale_x_continuous(guide = "none",  limits = c(-0.5,1.25)) +
  labs(x = "", y = "") + 
  theme(
    panel.background = element_rect(fill=bg), 
    plot.background = element_rect(fill=bg, color=NA), 
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    legend.background = element_rect(fill=bg), 
    legend.box.background = element_rect(fill=bg) )
```

:::
::::


## Treatment of deficiencies {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }

::: data-id="aspdlf" 
Identification
: a _process_ that provides a guarantee of identifying all deficiencies 

Effect quantification
: Estimation of effect of the deficiency on the statistical estimator

Additional uncertainty
: uncertainty attributed to uncertainty in the estimated effect size

Classification / allocation
: Attribution of additional uncertainty to specific types of deficiencies

:::
:::

::: {.column width="50%" .r-fit-text}

![](/media/moc_aa_generic.drawio.svg)

:::
::::

## Identification {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text }
::: data-id="aspdlf" 
Identification
: a _process_ that provides a guarantee for identifying all deficiencies 
:::

:::

::: {.column width="50%" .r-fit-text}

::: {.callout-note data-id="tre"}
### EBA/GL/2017/16 $\S$ 36. 
_Institutions should identify **all** deficiencies related to the estimation of risk parameters_
:::
:::
::::

::: {.callout-warning}
 * Leverage existing controls (Review of Est., DQ monitoring, MV)
 * Ensure & document minimally considered deficiencies
 * Identify requirements in order to establish deficiencies
:::


::: fragment
::: {.callout-important icon=true appearance="default" .r-fit-text}
## Common pitfalls
 * Forgetting/not documenting one of the required dimensions
 * Including *issues* that are not *deficiencies*
 * In particular, non-compliance
:::
:::

# Model performance & accuracy

## Model performance & accuracy {auto-animate=true .smaller}

::: {data-id="rty123"}
In case of...

 * Biases at level of calibration

 * Biases at more granular level 

 * Non-homogeneity of grades / sub-ranges

 * Non-heterogeneous grades
:::

::: fragment
::: {.callout-note}
### EBA/GL/2017/16 (Q&A p128) 
_The reference to ‘rank order estimation error’ has been deleted from the final GL. Instead, it has been clarified that, while data and methodological deficiencies in the model development should be identified, they should be covered by MoC to the extent that they lead to bias in the quantification of risk parameters or to increased uncertainty that is not fully captured by general estimation error._
:::
:::


## Model performance & accuracy {auto-animate=true .smaller}

:::: columns
:::{.column width="66%" .r-fit-text}
::: {data-id="rty123"}
In case of...

::: {.highlight-block data-id="sdf"}

 * Biases at level of calibration

$\rightarrow$ change method of calibration (remediation)
:::

 * Biases at more granular level 

 * Non-homogeneity of grades / sub-ranges

 * Non-heterogeneous grades

:::
:::
:::{.column width="33%"}

```{r wrong-adj-dist}
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 5

library(ggplot2) 
library(ggdist)
library(distributional)
#bg <- rgb(255,255,230, maxColorValue = 255)
bg <- 'transparent'
df <- data.frame(
  group = c("initial", "inappropriate", "inappropriate"), mu = c(0,0.5,0.8), sd = c(0.1,0.1,0.2), alpha=c(1, 0,1))

ggplot(df, aes(y = group, xdist = dist_normal(mu, sd))) +
  stat_halfeye(data=df[c(1,3),],aes(fill = stat(level), alpha=alpha)) +
  geom_segment(data=df[3,],
    aes(x = 0, xend = mu, yend = group), 
    color = "rosybrown", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed"), position=position_nudge(y=-0.05)) +
  geom_segment(data=df[3,],
    aes(x = mu, xend = mu-0.3, yend = group), 
    color = "skyblue", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed" ), position=position_nudge(y=-0.1)) +
  geom_vline(xintercept = df[1,]$mu, color = "gray", linetype="dashed" )+
  geom_vline(xintercept = df[2,]$mu, color = "rosybrown", linetype="dashed" )+
  scale_fill_manual(values = c("gray85", "skyblue"), na.value = "gray85", guide = "none") +
  scale_y_discrete() +
  scale_alpha(guide="none", range = c(0.33,0.75)) +
  scale_x_continuous(guide = "none",  limits = c(-0.5,1.25)) +
  labs(x = "", y = "") + 
  theme(
    panel.background = element_rect(fill=bg), 
    plot.background = element_rect(fill=bg, color=NA), 
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    legend.background = element_rect(fill=bg), 
    legend.box.background = element_rect(fill=bg) )
```


:::
::::

::: {.callout-important icon=true appearance="default" .r-fit-text}
## Common pitfalls
 * Bias at calibration level $=$ deficiency in model calibration method
 * Correction of calibration method $\neq$ appropriate adjustment

[No MoC for bias at calibration level!]{style="color:indianred"}
:::

## Model performance & accuracy {auto-animate=true .smaller}

:::: columns
:::{.column width="66%" .r-fit-text}
In case of...

 * Biases at level of calibration

::: {.highlight-block data-id="sdf"}

 * Biases at more granular level 
 * Non-homogeneity of grades / sub-ranges

$\rightarrow$ representativeness in terms of risk characteristics

::: 

 * Non-heterogeneous grades
:::
:::{.column width="33%"}
```{r non-hom-grade}
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 5

library(ggplot2) 
library(ggdist)
library(distributional)
#bg <- rgb(255,255,230, maxColorValue = 255)
bg <- 'transparent'
df <- data.frame(
  group = c("calibration level", "grade 1", "grade 2"), mu = c(0.5,0,1), sd = c(0.1,0.2,0.2), alpha=c(1, 0,0))

ggplot(df, aes(y = group, xdist = dist_normal(mu, sd))) +
  stat_halfeye(aes(fill = stat(level), alpha=alpha)) +
  geom_segment(data=df[2:3,],
    aes(x = 0.5, xend = mu, yend = group), 
    color = "rosybrown", 
    arrow = arrow(angle=20,length = unit(0.03, "npc"), type="closed"), position=position_nudge(y=-0.05)) +
  geom_vline(xintercept = df[1,]$mu, color = "gray", linetype="dashed" )+
  scale_fill_manual(values = c("gray85", "skyblue"), na.value = "gray85", guide = "none") +
  scale_y_discrete() +
  scale_alpha(guide="none", range = c(0.33,0.75)) +
  scale_x_continuous(guide = "none",  limits = c(-0.5,1.5)) +
  labs(x = "", y = "") + 
  theme(
    panel.background = element_rect(fill=bg), 
    plot.background = element_rect(fill=bg, color=NA), 
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    legend.background = element_rect(fill=bg), 
    legend.box.background = element_rect(fill=bg) )
```


:::
::::

::: {.callout-note icon=true appearance="default" .r-fit-text}
## Effect on calibration target?
 * effect on calibration target if distribution over grades/sub-ranges is non-representative of application portfolio
 * Representativeness assessments + accuracy tests $\rightarrow$ identification
:::

## Model performance & accuracy {auto-animate=true .smaller}
:::: columns
:::{.column width="66%" .r-fit-text}
In case of...


 * Biases at level of calibration

 * Biases at more granular level 
 * Non-homogeneity of grades / sub-ranges

::: {.highlight-block data-id="sdf"}
 * Non-heterogeneous grades

$\rightarrow$ nothing (no effect on risk quantification)
:::
:::
::: {.column width="33%" .r-fit-text }

```{r non-het-grade}
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 5

library(ggplot2) 
library(ggdist)
library(distributional)
#bg <- rgb(255,255,230, maxColorValue = 255)
bg <- 'transparent'
df <- data.frame(
  group = c("grade 2", "grade 1"), mu = c(0.55,0.45), sd = c(0.2,0.2), alpha=c(1, 1))

ggplot(df, aes(y = group, xdist = dist_normal(mu, sd))) +
  stat_halfeye(aes(fill = stat(level), alpha=alpha)) +
  geom_vline(aes(xintercept = mu), color = "gray", linetype="dashed" )+
  scale_fill_manual(values = c("gray85", "skyblue"), na.value = "gray85", guide = "none") +
  scale_y_discrete() +
  scale_alpha(guide="none", range = c(0.33,0.75)) +
  scale_x_continuous(guide = "none",  limits = c(-0.5,1.5)) +
  labs(x = "", y = "") + 
  theme(
    panel.background = element_rect(fill=bg), 
    plot.background = element_rect(fill=bg, color=NA), 
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    legend.background = element_rect(fill=bg), 
    legend.box.background = element_rect(fill=bg) )
```

:::
::::

::: {.callout-warning appearance="default" .r-fit-text}
## Still deficient
 * Reflected in general estimation error $\rightarrow$ not a "deficiency"
 * Still need to fullfill requirements w.r.t. meaningful differentiation
:::

# Data Quality & Completeness

## Data Quality & Completeness

:::: columns

::: {.column width="50%" .r-fit-text }
### Missing or inaccurate...

 * reference dates
 * attributes identifying type of exposures
 * (risk) characteristics $X_{ir}$ for assigning exposures
 * loss & default characteristics $\text{y}_{i}(t_r)$
   + over observation windows
   + cash flows

:::

::: {.column width="50%" .r-fit-text }
![](/media/data_requirements.drawio.svg)
:::

::::

![](/media/rds_aggr_general_cond.drawio.svg){fig-align="center"}


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text #vcenter }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
 * Reference data set $e:\{i,t\}$ with $y_{it},X_{it}, Z_{it}, \dots$
 * For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
 * Rating grade cannot be determined $\rightarrow$ potential bias at rating grade level
    + (no model for missing $X$ in ranking method)
:::
::::
::: fragment
::: {.callout-note .smaller}
### EBA/GL/2017/16 (p16)
_Data exclusions may be a tool to quantify adjustments to the observed average default and loss rates where these are necessary; however, they should never be taken into account for the purpose of calculating the observed average default rate_
:::
:::

## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text #vcenter }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {.callout-note .smaller}
### EBA/GL/2017/16 (p16)
_Data exclusions may be a tool to quantify adjustments to the observed average default and loss rates where these are necessary; however, they should never be taken into account for the purpose of calculating the observed average default rate_
:::


::: fragment
::: {.callout-important icon=true appearance="default" .r-fit-text}
## Common pitfall
 * Exclusion due to low-quality data without estimation of adjustment and MoC
:::
:::


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text #vcenter }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal" .smaller}
**Example: missing completely at random**

 * mechanism consistent with MCAR
 * distributions $y_{it}|Z_{it}$ similar over $f$, $g$
 * $\bar{y}^{(g)} \approx \bar{y}^{(e)}$ at calibration segment level

:::

## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example: missing completely at random**

#### (imputation)

:::

::: {.column width="75%" .r-fit-text }
 1. Calculate grade $a$ adjusted calibration target $\bar{y}_{a}^{(g)}$
 1. $\hat{\sigma}_{a}^{(g)}(y)=(N_{a}^{(g)}-1)^{-\tfrac{1}{2}} s_a^{(g)}$ includes addn. uncertainty
 1. Impute $X^{(f)} \sim X^{(g)}$ to obtain $\hat{\sigma}_{a}^{\prime(e)}(y)$
 1. Attribute $\Delta$ MoC A $\propto (\hat{\sigma}_{a}^{(g)}-\hat{\sigma}_{a}^{\prime(e)})$ 
:::
::::
:::


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example: missing completely at random**

#### (imputation)

:::

::: {.column width="75%" .r-fit-text }
Impute $X^{(f)} \sim X^{(g)}$ to obtain $\hat{\sigma}_{a}^{\prime(e)}(y)$

Attribute $\Delta$ MoC A $\propto (\hat{\sigma}_{a}^{(g)}-\hat{\sigma}_{a}^{\prime(e)})$ 
:::
::::
:::

::: {style="color:sienna" .smaller}
**Example (2): missing at random, linear estimates**

:::


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example: missing completely at random**

#### (imputation)

:::

::: {.column width="75%" .r-fit-text }
Impute $X_{js} \sim \text{Normal}(\bar{X}^{(g)}_a,\hat{\sigma}^{(g)}_a(X))$ to obtain $\hat{\sigma}_{a}^{\prime(e)}(y)$

Attribute $\Delta$ MoC A $\propto (\hat{\sigma}_{a}^{(g)}-\hat{\sigma}_{a}^{\prime(e)})$ 
:::
::::
:::

::: {style="color:sienna" .smaller}
:::: columns

::: {.column width="75%" .r-fit-text }

**Example (2): missing at random, linear estimates**

 * $P(\text{missing})=P(\text{missing}|X,Z,\dots)$
 * However, distributions $y_{it}$ **not** similar over $f$ vs $g$
 * Therefore, $\bar{y}_{a}^{(g)}$ is biased and cannot be used
 * Assume in addition that $p(a)\sim \alpha X + \beta$ (linear ranking model) 
:::

::: {.column width="25%" .r-fit-text }
:::
::::
:::


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example: missing completely at random**

#### (imputation)

:::

::: {.column width="75%" .r-fit-text }
Impute $X_{js} \sim \text{Normal}(\bar{X}^{(g)}_a,\hat{\sigma}^{(g)}_a(X))$ to obtain $\hat{\sigma}_{a}^{\prime(e)}(y)$

Attribute $\Delta$ MoC A $\propto (\hat{\sigma}_{a}^{(g)}-\hat{\sigma}_{a}^{\prime(e)})$ 
:::
::::
:::

::: {style="color:sienna" .smaller}
:::: columns

::: {.column width="25%" .r-fit-text }

**Example (2): missing at random, linear estimates**

#### (naive imputation)
:::

::: {.column width="75%" .r-fit-text }
 1. Impute $X_{js} \leftarrow \bar{X}^{(g)}_a$ to obtain $\bar{y}_{a}^{\prime(e)}$
 1. Impute $X_{js} \leftarrow \bar{X}^{(g)} + z_\alpha \hat{\sigma}^{(g)}_a$ to obtain $\bar{y}_{a}^{\prime(e)(\text{upper})}$
 1. MoC A $\propto \bar{y}_{a}^{\prime(e)(\text{upper})}-\bar{y}_{a}^{\prime(e)}$

:::
::::
:::

:::fragment
::: {.callout-note .smaller}
### EBA/GL/2017/16 (p178)
_$\small{\dots}$ adjusting the data where deficiencies have been identified may involve rectifying the identified errors, for instance where missing data points are filled in with the most probable information._
:::
:::



## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example: missing completely at random**

#### (imputation)

:::

::: {.column width="75%" .r-fit-text }
Impute $X_{js} \sim \text{Normal}(\bar{X}^{(g)}_a,\hat{\sigma}^{(g)}_a(X))$ to obtain $\hat{\sigma}_{a}^{\prime(e)}(y)$

Attribute $\Delta$ MoC A $\propto (\hat{\sigma}_{a}^{(g)}-\hat{\sigma}_{a}^{\prime(e)})$ 
:::
::::
:::

::: {style="color:sienna" .smaller}
:::: columns

::: {.column width="25%" .r-fit-text }

**Example (2): missing at random, linear estimates**

#### (naive imputation)
:::

::: {.column width="75%" .r-fit-text }
Impute $X_{js} \leftarrow \bar{X}^{(g)}_a$, $X_{js} \leftarrow \bar{X}^{(g)} + z_\alpha \hat{\sigma}^{(g)}_a$

$\Delta$ MoC A $\propto \bar{y}_{a}^{\prime(e)(\text{upper})}-\bar{y}_{a}^{\prime(e)}$
:::
::::
:::


::: {style="color:olive" .smaller}
**Example (3): missing at random, non-linear**

:::


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

::: {style="color:teal"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example: missing completely at random**

#### (imputation)

:::

::: {.column width="75%" .r-fit-text }
Impute $X_{js} \sim \text{Normal}(\bar{X}^{(g)}_a,\hat{\sigma}^{(g)}_a(X))$ to obtain $\hat{\sigma}_{a}^{\prime(e)}(y)$

Attribute $\Delta$ MoC A $\propto (\hat{\sigma}_{a}^{(g)}-\hat{\sigma}_{a}^{\prime(e)})$ 
:::
::::
:::

::: {style="color:sienna" .smaller}
:::: columns

::: {.column width="25%" .r-fit-text }

**Example (2): missing at random, linear estimates**

#### (naive imputation)
:::

::: {.column width="75%" .r-fit-text }
Impute $X_{js} \leftarrow \bar{X}^{(g)}_a$, $X_{js} \leftarrow \bar{X}^{(g)} + z_\alpha \hat{\sigma}^{(g)}_a$

$\Delta$ MoC A $\propto \bar{y}_{a}^{\prime(e)(\text{upper})}-\bar{y}_{a}^{\prime(e)}$
:::
::::
:::



::: {style="color:olive" .smaller}
:::: columns

::: {.column width="85%" .r-fit-text }

**Example (3): missing at random**

 * $P(\text{missing})=P(\text{missing}|X,Z,\dots)$
 * Distributions $y_{it}$ **not** similar over $f$ vs $g$
 * Calibration targets not linear in $X^{(f)}$ so that $E(\bar{y}_{a}^{(e)})\neq \bar{y}_{a}^{(e)}|_{X^{(f)}=\bar{X}^{(g)}}$

:::
::: {.column width="15%" .r-fit-text }
:::
::::
:::

::: aside
:::


## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

:::: columns
::: {.column width="33%" .r-fit-text }
::::: {style="color:teal"}
**Example: missing completely at random**
:::::
#### (imputation)

:::

::: {.column width="33%" .r-fit-text }
::::: {style="color:sienna"}
**Example (2): missing at random, linear estimates**
:::::
#### (naive imputation)
:::
::: {.column width="33%" .r-fit-text }
:::
::::

::::: {style="color:olive"}
:::: columns
::: {.column width="25%" .r-fit-text }
**Example (3): missing at random**

#### (multiple imputation)

:::

::: {.column width="75%" .r-fit-text }
Approximate $\bar{y}^{(e)}(X^{(f)},\dots)P(X^{(f)},\dots)$ with univariate resampling:

 1. Randomly sample $X^{(b)}$ from $X^{(g)}$ with replacement $M$ times
 1. Calculate $\bar{y}_a^{\prime(b)}=\bar{y}_a^{(e)}|_{X^{(f)}\leftarrow X^{(b)}}$, $y_a^{\prime}=\frac{1}{M}\sum_b y_a^{\prime(b)}$ (adj. calib. targets)
 1. Obtain the *excess variance*[^1] due to missing values as $\hat{\sigma}_M(\bar{y})=(1+\frac{1}{M})\sum_b\frac{(y_a^{\prime} -y_a^{\prime(b)})}{M-1}$

[^1]: See Rubin, D. B. (1987) *Multiple Imputation for Nonresponse in Surveys*

:::
::::
:::::



## Data Quality & Completeness  {auto-animate=true}

:::: columns

::: {.column width="33%" .r-fit-text }

::: {.highlight-block} 
Missing (risk) characteristics $X_{ir}$ for assigning exposures
:::

:::

::: {.column width="67%" .r-fit-text }
For exposures at reference dates $f:\{j,s\}$, variable $X_{js}$ missing ($g$ not missing)
:::
::::

:::: columns
::: {.column width="33%" .r-fit-text }
::::: {style="color:teal"}
**Example: missing completely at random**
:::::
#### (imputation)

:::

::: {.column width="33%" .r-fit-text }
::::: {style="color:sienna"}
**Example (2): missing at random, linear estimates**
:::::
#### (naive imputation)
:::
::: {.column width="33%" .r-fit-text }
::::: {style="color:olive"}

**Example (3): missing at random**
:::::
#### (multiple imputation)

:::
::::

:::{.callout-note appearance="default"}
## Real life
 * Real life usually not so fortunate {{< fa frown >}}
 * Identification of missingness mechanism important
 * Small effect expected $\rightarrow$ less sophisticated approaches
:::


::: fragment
::: {.callout-important icon=true appearance="default" .r-fit-text}
## Common pitfalls
 * Reliance on strong assumptions irrespective of materiality
:::
:::


# Representativeness

## Representativeness {auto-animate=true}

:::: columns

::: {.column width="67%" .r-fit-text }

 * Data should be *representative* of application portfolio 
   + Exposures, risk characteristics
   + (Risk management) processes (origination, DoD, recovery)
   + Economic/market conditions
 * EBA specifies dimensions minimally to be considered
 * Over all reference dates and exposures, per risk parameter
 
:::
::: {.column width="33%" .r-fit-text }
:::
::::

:::fragment
::: {.callout-note}
### EBA/GL/2017/16 $\S$ 34
_Where the representativeness of data $\small{\dots}$ is insufficient and leads to a bias or increased uncertainty of risk quantification, institutions should introduce an appropriate adjustment to correct the bias and they should apply a margin of conservatism_
:::
:::

## Representativeness {auto-animate=true}

:::: columns

::: {.column width="67%" .r-fit-text }

 * Data should be *representative* of application portfolio 
   + Exposures, risk characteristics
   + [(Risk management) processes (origination, DoD, recovery)]{style="color:indianred"}
   + Economic/market conditions
 * EBA specifies dimensions minimally to be considered
 * Over all reference dates and exposures, per risk parameter
 
:::
::: {.column width="33%" .r-fit-text }
::: {.callout-important appearance="default"}
### Challenges
 * Many potential deficiencies
 * Effects hard to model / quantify
 * Often no data available to estimate
:::
:::
::::

::: {.callout-tip appearance="default" .smaller}
## Strategies
**all** Qualitative assessment of potential drivers

**if so** Quantitative assessment of *non-representativeness* (according to some simple metric)

**finally** Quantitative estimate of *effect* of non-representativeness
:::


## Representativeness {auto-animate=true}

:::: columns

::: {.column width="67%" .r-fit-text }

 [(Risk management) processes (origination, DoD, recovery)]{style="color:indianred"}
 
:::
::: {.column width="33%" .r-fit-text }
::: {.callout-important appearance="default"}
### Challenges
 * Many potential deficiencies
 * Effects hard to model / quantify
 * Often no data available to estimate
:::
:::
::::

::: {.smaller .r-fit-text data-id="sdfsdf"}
Origination
: lending/underwriting standards, risk appetite, 

Default
: definition of default, policy and processes

Recovery
: recovery, restructuring, forbearance policies and processes
:::



## Representativeness {auto-animate=true}

:::: columns

::: {.column width="67%" .r-fit-text }

::: {.smaller .r-fit-text data-id="sdfsdf"}
Origination
: lending/underwriting standards, risk appetite, 

Default
: definition of default, policy and processes

Recovery
: recovery, restructuring, forbearance policies and processes
:::
 
:::
::: {.column width="33%" .r-fit-text }
::: {.callout-important appearance="default"}
### Challenges
 * Many potential deficiencies
 * Effects hard to model / quantify
 * Often no data available to estimate
:::
:::
::::




## Representativeness {auto-animate=true}

:::: columns

::: {.column width="67%" .r-fit-text }

::: {.smaller data-id="sdfsdf"}

:::{style="color:teal"}
Default
: definition of default, policy and processes
:::

:::
 
:::
::: {.column width="33%" .r-fit-text }
::: {.callout-note appearance="default"}
### Definition of default
 * EBA harmonization of DoD

:::
:::
::::

:::: columns

::: {.column width="67%" .r-fit-text }

### Common strategies (DoD)
 * Simulation based on historical data
 * Adjustments modelled on data collected under new DoD
 * Combinations
   + simulated materiality threshold
   + additional adjustment for UtP based on recent data

:::
::: {.column width="33%" .r-fit-text }
::: fragment
::: {.callout-warning appearance="default"}
### Pay attention
 * Simulation = appropriate adjustment
 * Recovery processes also affected
:::
:::
:::
::::


# Case Study Explanation 

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=true}

#### Introduction

In this exercise, you will estimate an appropriate adjustment and MoC A to account for a difference between the `New` DoD to be used in application and the `Old` DoD available in historical data. Fortunately, some data is available that was collected under both definitions. This is a (simulated) data set of a homogeneous portfolio, and there are no risk drivers, grades or other features to distinguish the exposures by. Lucky you!

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

::: {style="color:darkgrey"}

 * `New` DoD to be used in application and the `Old` DoD available in historical data
 * Estimate an appropriate adjustment and MoC A
:::

#### Data

You are given a panel data set with a set of $\approx$ 2k exposures `i` at 120 dates (months) `t` and default flags `d` according to a `New` and `Old` definition of default (`DoD`). The `New` definition is available only for the last 26 dates (months) whereas the `Old` definition default flag is available for the entire period. Two other derived variables are included for your convenience: a 12-month forward-looking into-default flag `into_d_12`, and a `status`: `enter`, `stock`, `default` or `exit`.

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

::: {style="color:darkgrey"}

 * `New` DoD to be used in application and the `Old` DoD available in historical data
 * Estimate an appropriate adjustment and MoC A
:::

#### Data

You are given a panel data set with a set of $\approx$ 2k exposures `i` at 120 dates (months) `t` and default flags `d` according to a `New` and `Old` definition of default (`DoD`). The `New` definition is available only for the last 26 dates (months) whereas the `Old` definition default flag is available for the entire period. Two other derived variables are included for your convenience: a 12-month forward-looking into-default flag `into_d_12`, and a `status`: `enter`, `stock`, `default` or `exit`.

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

:::: columns
::: {.column width="50%" .r-fit-text }
::: {style="color:darkgrey"}

 * `New` DoD to be used in application and the `Old` DoD available in historical data
 * Estimate an appropriate adjustment and MoC A
:::

`i`: exposure id

`t`: time

`DoD`: "Old" or "New"

`d`: in-default

`into_d_12`: into default within 12 months

`status`: `enter`, `stock`, `default` or `exit`
:::
::: {.column width="50%" .r-fit-text .smaller}

```{r}
library(dplyr)
case_study_1_data <- read.csv("../../media/case_study_1_data.csv.gz")
``` 

```{r echo=FALSE}
#| tbl-cap: "sample of 10 exposures" 

case_study_1_data |>
  filter(i %in% sample(i,10)) |> 
  as.data.frame()
```

:::
::::


```{r }
library(downloadthis)
case_study_1_data |>
  download_this( 
    output_name = "case study 1 data",
    output_extension = ".csv",
    button_label = " Download data as csv",
    button_type = "success",
    has_icon = TRUE,
    icon = "fa fa-save"
  )
``` 
```{r}
case_study_1_data |>
  download_this( 
    output_name = "case study 1 data",
    output_extension = ".xlsx",
    button_label = "Download data as xlsx",
    button_type = "success",
    has_icon = TRUE,
    icon = "fa fa-save"
  )
```

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

::: {style="color:darkgrey"}

 * `New` DoD to be used in application and the `Old` DoD available in historical data
:::

#### Challenge

 * Estimate **appropriate adjustment** to the `Old` DoD data to estimate the appropriately adjusted long-run average default rate, 
 * Also estimate the additional uncertainty due to this adjustment. 

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

::: {style="color:darkgrey"}

 * `New` DoD to be used in application and the `Old` DoD available in historical data
 * Estimate an appropriate adjustment and MoC A
:::

#### Challenge
Do so under different assumptions/scenarios:

 A) First, assume that $\bar{R}^{(new)}_{(12)} = \alpha \bar{R}^{(old)}_{(12)} + \epsilon$, where $\bar{R}_{(n)}$ is an observed average $n$-month into-default rate. In words, assume that any average default rate over a fixed period under the new default definition is a constant factor times that under the old one.

 B) Alternatively, assume that $R^{(new)}_{(1)}(t) = \beta R^{(old)}_{(1)}(t) + \epsilon$, where $R_{(n)}(t)$ is the observed $n$-month into-default rate at reference date $t$. In words, assume that not the long-run average 12-month, but the monthly into-default rate under the new definition is related to the old one with a constant scale factor $\beta$.

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

::: {style="color:darkgrey"}
 * `New` DoD to be used in application and the `Old` DoD available in historical data
 * Estimate an appropriate adjustment and MoC A
 * Scenario A: $\bar{R}^{(new)}_{(12)} = \alpha \bar{R}^{(old)}_{(12)} + \epsilon$
 * Scenario B: $R^{(new)}_{(1)}(t) = \beta R^{(old)}_{(1)}(t) + \epsilon$
:::

#### Challenge
For each of these two scenarios,

 1) Estimate $\alpha$ resp. $\beta$ based on the overlapping period.
 2) Based on your estimates, derive appropriately adjusted default rates.
 3) Also estimate the uncertainty[^1] of $\alpha$ resp. $\beta$.
 4) Using error propagation, derive the corresponding **additional** uncertainty of the estimated appropriately adjusted long-run average default rate in either case.

## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

::: {style="color:darkgrey"}
 * `New` DoD to be used in application and the `Old` DoD available in historical data
 * Estimate an appropriate adjustment and MoC A
 * Scenario A: $\bar{R}^{(new)}_{(12)} = \alpha \bar{R}^{(old)}_{(12)} + \epsilon$
 * Scenario B: $R^{(new)}_{(1)}(t) = \beta R^{(old)}_{(1)}(t) + \epsilon$
:::

#### BONUS QUESTIONS

 5) Would you consider the assumptions A) and B) to be reasonable in a real-life situation? Can you verify these assumptions using the given data?
 6) Can you come up with an alternative approach?
 7) Your appropriately adjusted LRA DR may be more uncertain due to model misspecification. Can you think of some ways to quantify that uncertainty?
 8) This simulated data set has only idiosyncratic variability, i.e., there is no systemic risk factor! Do your answers to the previous questions change?


## Case study 1: one Dod, two Dod {.smaller .r-fit-text auto-animate=truie}

 1. Download the data from slides or ask for email
 1. Use your favorite tool to get an answer.
 1. Share your answers by coming Friday