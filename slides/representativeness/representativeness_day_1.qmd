---
title: "Representativeness"
subtitle: "Day 1"
author: "Pieter van den Berg"
date: 2023-09-25
date-format: long
format: eduquant-slides-revealjs
---



{{< include ../_sections/introductions.qmd >}}

# Course Outline 

## Course outline

::: columns
::: {.column #vcenter width="15%"}
[Day 1]{style="color: darkseagreen;"}
:::

::: {.column #vcenter width="85%"}
Risk Parameter Estimation Overview

Data Representativeness Overview

Scope of Application
:::
:::

::: columns
::: {.column #vcenter width="15%"}
[Day 2]{style="color: darkseagreen;"}
:::

::: {.column #vcenter width="85%"}
General Process Design

Definition of Default

Underwriting/Recovery Standards
<!-- Estimation Process Design

Definition of Default

Underwriting/Lending Standards

Recovery Process/Standards

Case Study -->
:::
:::

::: columns
::: {.column #vcenter width="15%"}
[Day 3]{style="color: darkseagreen;"}
:::

::: {.column #vcenter width="85%"}
Economic Conditions 

External Data/Ratings
<!-- 
Economic Conditions 

Range of Variability of Default Rates

External / Pooled Data

Use of ECAI ratings

Case Study -->
:::
:::

::: columns
::: {.column #vcenter width="15%"}
[Day 4]{style="color: darkseagreen;"}
:::

::: {.column #vcenter width="85%"}
Review of Estimates & IRB Change

Governance
<!-- Risk Characteristics

Review of Estimates & IRB Change Process

Governance

Discussion -->


:::
:::


## Day 1

::: columns
::: {.column width="15%"}
*13:00*

*13:30*

*14:30*

*15:30*

*16:30*

:::

::: {.column width="85%"}
Introduction

Risk Parameter Estimation Overview

Representativeness Overview

Scope of Application

Case Study
:::
:::
::: footer
```{r }
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 4
library(qrcode)
code <- qr_code("https://quantprofessionals.github.io/eduquant-courses/slides/representativeness/representativeness_day_1.html")
plot(code)
```
[https://tinyurl.com/4n5hj2vw](https://tinyurl.com/4n5hj2vw)
:::

<!-- 
# Risk Parameter Estimation

## Rating Systems {auto-animate=true}

:::: columns

::: {.column #vcenter  width="50%" .r-fit-text data-id=x1}
Rating System
: assessment methods & processes developed for a certain type of exposures

Type of Exposures
: homogeneously managed, comparable risk characteristics

Range of Application
: all exposures of the type in scope of the rating system  

Calibration Segment
: level of risk quantification $\subset$ scope of application

Ranking method
: Risk differentiation model

Grades/Pools
: Exposures with similar risk profiles
:::

::: {.column #vcenter  width="50%"  .r-fit-text}
![](/media/irb_overview.drawio.svg)

:::

:::: -->


## Risk Parameter Estimation {auto-animate=true}

:::: columns

::: {.column #vcenter  width="50%" vertical-align="middle" .r-fit-text}

:::{data-id=a1}
Indirect estimation
: risk quantification conditional on risk differentiation
:::

:::{data-id=a2}
Risk Differentiation
: differentiate and rank exposures on (internal) risk measure
:::

:::{data-id=a3}
Risk Quantification
: Quantify risk parameter estimates; calibration to long-run or downturn estimates and MoC
:::

:::

::: {.column #vcenter  width="50%" }
![](/media/differentiation_quantification_small.drawio.svg){fig-align="center"}
:::

::::

::: notes
Diagram: differentiation -\> quantification
:::

::: notes
14:00
:::


## Risk Parameter Estimation {auto-animate=true}

:::: columns
::: {.column #vcenter   width="50%"  .r-fit-text}
:::{data-id=a1}
Indirect estimation
: risk quantification conditional on risk differentiation
:::
:::{data-id=a2}
Risk Differentiation
: differentiate and rank exposures on risk measure
:::
:::{.highlight-block}
 * Risk measure $\sim$ into-default / realized LGD closed cases / realized CCF 
 * Conditional on risk drivers, based on data set representative of application portfolio
 * Regulatory requirements focus on *meaningful differentiation*
:::

:::{data-id=a3}
Risk Quantification
: Quantify risk parameter estimates; calibration to long-run or downturn estimates and MoC
:::

:::

::: {.column #vcenter width="50%" }
![](/media/differentiation_quantification_small.drawio.svg){fig-align="center"}
:::

::::

::: notes
Diagram: differentiation -\> quantification
:::

## Risk Parameter Estimation {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%"  .r-fit-text}

:::{data-id=a1}
Indirect estimation
: risk quantification conditional on risk differentiation
:::

:::{data-id=a2}
Risk Differentiation
: differentiate and rank exposures on risk measure
:::

:::{data-id=a3}
Risk Quantification
: Quantify risk parameter estimates; calibration to long-run or downturn estimates and MoC
:::

:::{.highlight-block}
 * Estimates of long-run default/loss experience
 * Regulatory requirements focus on *calculation method* and *quantification process*
:::
:::

::: {.column #vcenter width="50%" }
![](/media/differentiation_quantification_small.drawio.svg){fig-align="center"}
:::

::::

::: notes
Diagram: differentiation -\> quantification
:::

## Risk Parameter Estimation {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%"  .r-fit-text}

:::{data-id=a1}
Indirect estimation
: risk quantification conditional on risk differentiation
:::

:::{.highlight-block}
 * Direct estimation: special case
 * Continuous estimation: effectively same requirements 
:::

:::{data-id=a2}
Risk Differentiation
: differentiate and rank exposures on risk measure
:::

:::{data-id=a3}
Risk Quantification
: Quantify risk parameter estimates; calibration to long-run or downturn estimates and MoC
:::

:::

::: {.column #vcenter width="50%" .r-fit-text  }
![](/media/differentiation_quantification_small.drawio.svg){fig-align="center"}

::: {.callout-note .smaller}
## CRR Article 169
_3. Where an institution uses direct estimates of risk parameters for individual obligors or exposures these may be seen as estimates assigned to grades on a continuous rating scale._
:::
::: {.callout-note .smaller}
### Amendment
[_EBA shall issue guidelines on how to apply in practice the requirements on model
design, risk quantification, validation and application of risk parameters using
continuous or very granular rating scales for each risk parameter._]{style="color: darkorange;"}
:::
:::
::::

::: notes
14:15
:::

## Risk Parameter Quantification {auto-animate=true}

:::: columns

::: {.column width="50%" .r-fit-text}
Exposure type
: homogeneously managed, comparable risk characteristics

Reference dates
: Date to which realised values are aggregated

Calibration Target
: long-run average (LRA) default rate, (LRA/DT) LGD, CCF calculated based on RDS prior to adjustments

Appropriate Adjustment
: Modeled effect on CT of drivers of non-representativeness & other sources of bias

Appropriately Adjusted Calibration Target
: Calibration Target adjusted for biases

:::

::: {.column width="50%" .r-fit-text}
![](/media/risk_quantification.drawio.svg)
:::

::::

::: notes
Diagram: Type of Exposures -\> RDS -\> Initial Calibration Target -\> Appr. Adjusted Target

Par 12 PD&LGD
:::

::: notes
15:15
:::


## MoC Quantification {auto-animate=true}

:::: columns

::: {.column width="65%" .r-fit-text data-id="plo"}

*Initial* Calibration Target (CT)
: long-run average (LRA) default rate, (LRA/DT) LGD, CCF ~calculated~ estimated based on RDS prior to adjustments

MoC C
: Margin to account for statistical uncertainty of calibration target estimate in the absence of potential biases due to deficiencies

Deficiency
: Source of bias relative to initial calibration target

Appropriately adjusted calibration target
: Calibration target adjusted for biases due to deficiencies

MoC B
: Margin to account for additional uncertainty due to adjustment for non-representativeness

MoC A
: Margin to account for additional uncertainty due to other deficiencies
:::

::: {.column width="35%" .r-fit-text}
![](/media/risk_quantification_moc.drawio.svg)
:::

::::

## Reference Data Sets {auto-animate=true}

:::: columns

::: {.column width="65%" .r-fit-text}

Length of historical period
: min. requirements (5 or 7 yr) + available relevant internal data on comparable exposures

Reference date methodology
: (non-)overlapping [**PD**], time-to-default [**LGD**, **CCF**], recovery process [**in-default**]

Exposure attributes
: identify exposures of given type at historical observation dates

Default/loss characteristics
: Observed default/loss data aggregated by exposure over observation period at reference date (target variable)

Risk characteristics
: Risk drivers, appropriate adjustment variables

Observation windows
: aggregate to obtain targets (fwd) or variables (bwd) 

:::

::: {.column width="35%" .r-fit-text }
![](/media/reference_data_set.drawio.svg)

::: {.fragment .fade-in}
![](/media/rds_aggr_general.drawio.svg)
:::
:::
::::


## Realised Risk Parameter Values {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}

Reference date methodology
: (non-)overlapping [**PD**], time-to-default [**LGD**, **CCF**], time-in-default/recovery process [**in-default**]

Reference dates $t_r$
: set of dates over which calibration target is calculated, either as an average (LRA LGD), average of yearly averages (PD & LRA CCF), or an estimated downturn effect (DT LGD/CCF)

Default/Loss characteristics
: exposure-level into-default flag, (partially) realised LGD values, realised credit conversion factors, intermediate components


:::

::: {.column #vcenter width="50%"  .r-fit-text }
![](/media/rds_aggr_general.drawio.svg)

<!-- $\text{Cal. target} \sim \sum_{r}w_r\sum_{i\in\mathbf{L}}v_i y_i(t_r)$ -->

:::


::::

::: aside
Typical approach: realised values also targets of (statistical) ranking method (model)
:::


## Calibration Targets {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}

Length of historical period
: reflecting variability of economic conditions

Methodology
: overlapping versus non-overlapping

Reference dates $t_{r}$
: Sample over historical data representative of application portfolio conditioned on target

Calibration segment 
: level of aggregation (range of appl. $\supseteq$ calibration segment $\supset$ grade/pool)

Calibration target
: Prescribed estimator of LRA/DT risk parameter values
: (adjusted/weighted) average of realised risk parameter values

:::

::: {.column #vcenter width="50%" .r-fit-text}
![](/media/risk_quantification_simple.drawio.svg)
![](/media/rds_aggr_general_calib_target.drawio.svg)
:::


::::



## Calibration Targets {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}

Length of historical period
: reflecting variability of economic conditions

Methodology
: overlapping versus non-overlapping

Reference dates $t_{r}$
: Sample over historical data representative of application portfolio conditioned on target

Calibration segment 
: level of aggregation (range of appl. $\supseteq$ calibration segment $\supset$ grade/pool)

Calibration target
: Prescribed estimator of LRA/DT risk parameter values
: (adjusted/weighted) average of realised risk parameter values

:::

::: {.column #vcenter width="50%" .r-fit-text}
![](/media/rds_aggr_general_calib_target.drawio.svg)
<!-- ![](/media/rds_aggr_pd.drawio.svg) -->

$$\text{DR}(\mathbf{L}) = \frac{1}{R}\sum_{r=1\dots R}\frac{1}{N_\mathbf{L}(t_r)}\sum_{i\in\mathbf{L}} D_i(t_r)$$

$$\text{Observed LGD}(\mathbf{L}) = \frac{1}{N_\mathbf{L}}\sum_{i\in\mathbf{L}} \text{RLGD}_i$$

$$\text{CCF}(\mathbf{L}) = \frac{1}{R}\sum_{r=1\dots R}\frac{1}{N_\mathbf{L}(t_r)}\sum_{i\in\mathbf{L}} RCCF_i(t_r)$$

:::


::::



# Break

# Representativeness

## Representativeness {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}
| <!-- -->    | <!-- -->    |
|-------------|-------------|
|**Model**|relevant scope/conditions to describe generating process|
|**Data**|generated under historical realized conditions|
|**Predictions**|conditional on data generated with current conditions|

:::

::: {.column #vcenter width="50%" .r-fit-text}
![](/media/representativeness_simple.drawio.svg)
:::
::::
::: {.r-fit-text}
Modelling assumption
: _comparable_ scope & conditions $\rightarrow$ _representative_ data $\rightarrow$ _unbiased_ estimates
:::

## Representativeness {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}
 * Credit Risk data generating process
   - Specify how policies/conditions relate to credit processes
   - Not typically explicitly modelled
 * Scope/conditions listed in 
   - EBA/GL/2017/16 4.2.2, CDR 439 art. 37 (risk differentation)
   - EBA/GL/2017/16 4.2.3, CDR 439 art. 42 (quantification)
:::

::: {.column #vcenter width="50%" .r-fit-text}
![](/media/data_generating.drawio.svg)
:::

::::


## Representativeness {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}
* Credit Risk data generating process
  - Specify how policies/conditions relate to credit processes
  - Not typically explicitly modelled
 * Scope/conditions listed in 
   - EBA/GL/2017/16 4.2.2, CDR 439 art. 37 (risk differentation)
   - EBA/GL/2017/16 4.2.3, CDR 439 art. 42 (quantification)
:::

::: {.column #vcenter width="50%" .r-fit-text}
![](/media/data_generating.drawio.svg)
![](/media/rds_aggr_general_repn.drawio.svg)
:::

::::

## Representativeness {auto-animate=true}

:::: columns

::: {.column #vcenter width="30%" .r-fit-text}
| <!-- -->    | <!-- -->    |
|-------------|-------------|
|$y_{it}$|realized default/loss characteristics|
|$x_{it}$|risk drivers, ...|
|$\pi(\theta|y;x)$|parameter estimate|
|$\pi(y|\hat\theta;x)$|prediction|
:::

::: {.column #vcenter width="70%" .r-fit-text}
![](/media/representativeness_generic.drawio.svg)
:::
::::


## Representativeness {auto-animate=true}

:::: columns

::: {.column #vcenter width="25%" .r-fit-text}
| <!-- -->    | <!-- -->    |
|-------------|-------------|
|$y_{it}$|realized default/loss characteristics|
|$x_{it}$|risk drivers, ...|
|$\pi(\theta|y;x)$|parameter estimate|
|$\pi(y|\hat\theta;x)$|prediction|
:::

::: {.column #vcenter width="75%" .r-fit-text}
![](/media/representativeness_generic_counterfactual.drawio.svg)
:::
::::


## Regulatory Requirements {auto-animate=true}
### [Risk Differentiation]{style="color: darkcyan"}
:::: columns

::: {.column #vcenter width="40%" .r-fit-text }
 * Article 174 specifically worded
 * CDR 439 article 37 & EBA/GL/2017/16 4.2.2 comprehensive requirements 
:::

::: {.column #vcenter width="60%" .r-fit-text }

::::: {.callout-note}
## CRR Article 174
_If an institution uses statistical models and other mechanical methods to assign exposures to obligors or facilities grades or pools, the following requirements shall be met:$\small{[\cdots]}$_

_(c) the data used to build the model shall be representative of the population of the institution's actual obligors or exposures;_
:::::

::::: {.callout-note}
## EBA/GL/2017/16 par. 21
_$\small{[\cdots]}$ institutions should analyse the representativeness of the data at the stage of model development in terms of all of the following:_

_(a) the scope of application;_

_(b) the definition of default;_

_(c) the distribution of the relevant risk characteristics;_

_(d) lending standards and recovery policies._
:::::


<!-- ::::: {.callout-note}
## CDR 2022/439 Article 37(2)
_When assessing the representativeness of the data used to build the model as referred to in Article 174(c) of Regulation (EU) No 575/2013, competent authorities shall verify:_

_(a) the comparability of risk characteristics of the obligors or facilities reflected in the data used to build the model with those of the exposures covered by a particular rating model;_

_(b) the comparability of the current underwriting and recovery standards ith the ones applied at the time to which the reference data set used for the modelling relates;_

_(c) the consistency of default definition over time in the data used for the modelling $\small{[\cdots]}$_ (etc)

_(d) where external data or data pooled across institutions is used in the model development, the relevance and adequacy of such data for the institution’s exposures, products and risk profile_
::::: -->

:::

::::


## Regulatory Requirements {auto-animate=true}
### [Risk Quantification]{style="color: #0b3f5e"}
:::: columns

::: {.column #vcenter width="40%" .r-fit-text }

 * CRR article 179 more extensive
 * CDR 439 articles 42, EBA/GL/2017/16 4.2.4 set out required assessments more comprehensively
   - 4.2.4 _Representativeness of data for calibration of risk parameters_
 * Economic/market conditions
   - PD: likely range of variability of one-year default rates
   - LRA LGD: historical observation period (no adjustment)
   - DT LGD: Downturn identification
:::

::: {.column #vcenter width="60%" .r-fit-text }

::::: {.callout-note}
## CRR Article 179(1)
_In quantifying the risk parameters to be associated with rating grades or pools, institutions shall apply the following requirements:$\small{[\cdots]}$_

_(b) $\small{[\cdots]}$The institution's estimates shall be representative of long run experience;_

_(c) any changes in lending practice or the process for pursuing recoveries over the observation periods $\small{[\cdots]}$ shall be taken into account._

_(d) the population of exposures represented in the data used for estimation, the lending standards used when the data was generated and other relevant characteristics shall be comparable with those of the institution's exposures and standards. The economic or market conditions that underlie the data shall be relevant to current and foreseeable conditions._
:::::
<!-- :::: {.callout-note}
## CDR 2022/439 Article 42
_1. When assessing compliance with the overall requirements for estimation laid down in Article 179 $\small{[\cdots]}$, the data used for the quantification of risk parameters $\small{[\cdots]}$ compentent authorities shall verify:$\small{[\cdots]}$_

_(c) the representativeness of the data used to estimate the risk parameters for certain types of exposures;_

::::: -->
:::: {.callout-note}
## EBA/GL/2017/16 par. 28
_$\small{[\cdots]}$in terms of all of the following:_

_(a) the scope of application;_

_(b) the definition of default;_

_(c) the distribution of the relevant risk characteristics;_

**_(d) the current and foreseeable economic or market conditions;_**

_(e) lending standards and recovery policies._

::::


:::

::::
::: notes

:::


## Assessment & Estimation Procedure {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}

 1. Identify non-comparable scope/process/condition
 2. Assess non-representativeness data
 3. Estimate effect size & quantify adjusted calibration target
 4. Estimate additional uncertainty & quantify MoC
   - MoC A (Definition of Default)
   - MoC B (Other non-representativeness)


:::

::: {.column #vcenter width="50%" .r-fit-text}
::: {.callout-note}
### EBA/GL/2017/16 $\S$ 34
_Where the representativeness of data $\small{\dots}$ is insufficient and leads to a bias or increased uncertainty of risk quantification, institutions should introduce an appropriate adjustment to correct the bias and they should apply a margin of conservatism_
:::

![](/media/repr_methodology.drawio.svg)
:::

::::

::: notes
High level process

Identification of potential drivers of non-representativeness
Estimation of effect on risk estimation targets
Quantification of appropriate adjusted calibration target
Quantification of additional uncertainty

:::



## Assessment & Estimation Procedure {auto-animate=true}

:::: columns

::: {.column #vcenter width="50%" .r-fit-text}

 1. Identify non-comparable scope/process/condition
  - Identify potential drivers of bias
 2. Assess non-representativeness data
 3. Estimate effect size & quantify adjusted calibration target
 4. Estimate additional uncertainty & quantify MoC
   - MoC A (Definition of Default)
   - MoC B (Other non-representativeness)


:::

::: {.column #vcenter width="50%" .r-fit-text}
![](/media/repr_methodology.drawio.svg)
:::

::::




## Assessment & Estimation Procedure {auto-animate=true}

:::: columns

::: {.column #vcenter width="60%" .r-fit-text}
 (@) Qualitatively assess comparability scope/process/condition

##### Expert-based
 (@) Heuristically assess non-representativeness data

##### Model/simulation based
 2. Model/simulate comparable scope/process/condition
 3. Estimate effect size & quantify adjusted calibration target
 4. Estimate additional uncertainty & quantify MoC
   - MoC A (Definition of Default)
   - MoC B (Other non-representativeness)

:::

::: {.column #vcenter width="40%" .r-fit-text}
![](/media/repr_methodology.drawio.svg)
:::

::::


# Scope of Application

## Scope of Application {auto-animate=true}

:::: columns

::: {.column #vcenter width="40%" .r-fit-text }
Type of Exposures
: homogeneously managed, comparable risk characteristics

Range of Application
: all exposures of the type in scope of the rating system 
:::

::: {.column #vcenter width="60%" .r-fit-text }

::::: {.callout-note}
### EBA/GL/2017/16
_$\small{[\cdots]}$institutions should analyse the segmentation of exposures and consider whether there were any changes to the scope of application of the considered model over the period covered by the data used in developing the model for assigning obligors or exposures to grades or pools.$\small{[\cdots]}$_
:::::

::::: {.callout-note}
### CDR 439 art. 42(2)
_$\small{[\cdots]}$shall assess the representativeness of the data used to estimate the risk parameters for certain types of exposures by assessing:_

_(a) the structure of exposures covered by each rating model and the different risk characteristics of the obligors or facilities, and whether the current portfolio is, to the degree required, comparable to the portfolios constituting the reference data set$\small{[\cdots]}$_
:::::


:::
::::




## Scope of Application {auto-animate=true}

:::: columns

::: {.column #vcenter width="60%" .r-fit-text }
Type of Exposures
: homogeneously managed, comparable risk characteristics

Range of Application
: all exposures of the type in scope of the rating system 

#### Typical cases

 * historical scope of appliciation not aligned with intended
 * historical scope not well defined
 * exposures historically not managed homogeneously

:::

::: {.column #vcenter width="40%" .r-fit-text }

![](/media/scope_of_appl_analysis.drawio.svg)

![](/media/scope_of_appl_analysis_id.drawio.svg)


:::
::::



## Scope of Application {auto-animate=true}

:::: columns

::: {.column #vcenter width="60%" .r-fit-text }
### Favorable example
 * intended scope of application subset of historically applied
 * simply select data of exposures in scope
 * no further adjustments or MoC requiredc

:::

::: {.column #vcenter width="40%" .r-fit-text }

![](/media/scope_of_appl_analysis.drawio.svg)

![](/media/scope_of_appl_analysis_id.drawio.svg)


:::
::::




## Scope of Application {auto-animate=true}

:::: columns

::: {.column #vcenter width="60%" .r-fit-text }
### Less favorable example
 * historically applied subset of intended scope of application subset
 * e.g. subportfolios with different data availability
 
:::

::: {.column #vcenter width="40%" .r-fit-text }

![](/media/scope_of_appl_analysis.drawio.svg)

![](/media/scope_of_appl_analysis_id2.drawio.svg)


:::
::::




## Scope of Application {auto-animate=true}

:::: columns

::: {.column #vcenter width="60%" .r-fit-text }
### Less favorable example
 * historically applied subset of intended scope of application subset
 * e.g. subportfolios with different data availability
 
 1. Are subportfolios A & B comparable in terms of risk characteristics & management?
 2. Is data from period S representative of application portfolio?
 3. What is the effect on calibration target?
::: 

::: {.column #vcenter width="40%" .r-fit-text }
![](/media/scope_of_appl_analysis_id2.drawio.svg)


![](/media/scope_of_appl_analysis_id3.drawio.svg)


:::
::::



## Scope of Application {auto-animate=true}

:::: columns

::: {.column #vcenter width="60%" .r-fit-text }
### Less favorable example
 * historically applied subset of intended scope of application subset
 * e.g. subportfolios with different data availability
 
 1. Are subportfolios A & B comparable in terms of risk characteristics?
 2. Is data from period S representative of application portfolio?
 3. What is the effect on calibration targets?



::: 

::: {.column #vcenter width="40%" .r-fit-text }
![](/media/scope_of_appl_analysis_id2.drawio.svg)


![](/media/scope_of_appl_analysis_id3.drawio.svg)


:::
::::

# Case Study

## Case study {.smaller .r-fit-text auto-animate=true}
:::: columns

::: {.column #vcenter width="60%" .r-fit-text }

#### Introduction


In this exercise, you will **estimate an appropriate adjustment and MoC A** to account for the bias introduced by having a **non-comparable scope of application on certain historical reference dates**. 
::: 

::: {.column #vcenter width="40%" .r-fit-text }
![](/media/scope_of_appl_analysis_id2.drawio.svg)
:::
::::

::: fragment
 * Download the dataset from the slides website (`csv` or `xlsx`)
 * Use your favorite tool! Anything goes.
 * Bring the results for discussion to next week training
 * Or send them to [pieter@berg-sp.eu](mailto:pieter@berg-sp.eu)
::: 

## Case study: 2 portfolios, 1 data {.smaller .r-fit-text auto-animate=true}
:::: columns

::: {.column #vcenter width="60%" .r-fit-text }


#### Description

 * There are two subportfolios A and B
 * They have different default levels, otherwise each is homogeneous
 * Rather than modelling the differences, you *choose* to estimate a single LRA DR calibration target for the entire portfolio.

::: fragment
#### Assignment

 * Estimate an appropriately adjusted long-run average default rate
 * Bonus Points: calculate a MoC A
:::

::: fragment

#### Data

You are given a panel data set with a set of exposures `i` in subportfolio 'A' or 'B' at dates `t` and a default flag `d`. Two other derived variables are included for your convenience: a 12-month forward-looking into-default flag `into_d_12`, and a `status`: `enter`, `stock`, `default` or `exit`.
:::

::: 

::: {.column #vcenter width="40%" .r-fit-text }
![](/media/scope_of_appl_analysis_id2.drawio.svg)
:::

::::


## Case study: 2 portfolios, 1 data {.smaller .r-fit-text auto-animate=true}


:::: columns
::: {.column width="50%" .r-fit-text }


| column    | description    |
|-------------|-------------|
|`i`| exposure id|
|`t`| time|
|`subportfolio`| "A" or "B"|
|`d`| in-default|
|`into_d_12`| into default within 12 months|
|`status`| `enter`, `stock`, `default` or `exit`|
:::
::: {.column width="50%" .r-fit-text .smaller}

```{r}
library(dplyr)
case_study_2_data <- read.csv("../../media/case_study_2_data.csv.gz")
``` 

```{r echo=FALSE}
#| tbl-cap: "sample of 10 exposures" 

case_study_2_data |>
  filter(i %in% sample(i,10)) |> 
  as.data.frame()
```

:::
::::

:::: columns
::: {.column #vcenter width="50%" .r-fit-text }

```{r }
library(downloadthis)
case_study_2_data |>
  download_this( 
    output_name = "case study 2 data",
    output_extension = ".csv",
    button_label = " Download data as csv",
    button_type = "success",
    has_icon = TRUE,
    icon = "fa fa-save"
  )
``` 
```{r}
case_study_2_data |>
  download_this( 
    output_name = "case study 2 data",
    output_extension = ".xlsx",
    button_label = "Download data as xlsx",
    button_type = "success",
    has_icon = TRUE,
    icon = "fa fa-save"
  )
```

:::
::: {.column #vcenter width="50%" .r-fit-text }
```{r }
#| dev.args:
#|   bg: "transparent"
#| fig.asp: 1
#| fig.width: 3
library(qrcode)
code <- qr_code("https://quantprofessionals.github.io/eduquant-courses/slides/representativeness/representativeness_day_1.html#/case-study-2-portfolios-1-data-1")
plot(code)
```
[https://tinyurl.com/4n5hj2vw](https://tinyurl.com/4n5hj2vw)

:::

::::